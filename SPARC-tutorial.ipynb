{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fbbad7-cc5c-4fd5-bcc7-e5493398afcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **<center>SPARC FAIR Codeathon 2022</center>**\n",
    "<center>\n",
    "<a href=\"https://sparc.science\">\n",
    "<img src=\"https://sparc.science/_nuxt/img/logo-sparc-wave-primary.8ed83a5.svg\" alt=\"SPARC\" width=\"150\"/>\n",
    "</a>\n",
    "</center>\n",
    "<center>\n",
    "<a href=\"https://sparc.science/help/2022-sparc-fair-codeathon\">\n",
    "<img src=\"https://images.ctfassets.net/6bya4tyw8399/2qgsOmFnm7wYIfRrPrqbgx/ae3255858aa12bfcebb52e95c7cacffe/codeathon-graphic.png\" alt=\"FAIR\" width=\"75\">\n",
    "</a>\n",
    "</center>\n",
    "\n",
    "## <center>Mapping 2D **SPARC** data points to a 3D scaffold: a tutorial</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde64e8-4021-4a6b-bae7-b90b40239999",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Introduction**\n",
    "Welcome to the Quilted tutorial! We will be demonstrating different features from the [**SPARC**](https://sparc.science/) project. The goal will be to project the 2D locations of neurites in the rat stomach onto a 3D scaffhold of the organ. The data points and the 3D scaffhold will be pulled from **SPARC** datasets. Because the data is [**FAIR**](https://www.nature.com/articles/sdata201618) we will be combining three different datasets of the spatial distribution of the vagal afferents and efferents. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884dcdd0-fd61-4468-a8f2-d0ba9cf8b803",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Setting up a virtual environment**\n",
    "We assume that you have already followed the instructions in the **Getting started** section of the [README](https://github.com/SPARC-FAIR-Codeathon/SPARC-Tutorial).\n",
    "The first step will be to create a virtual environment in which we will be able to run this tutorial. We will install the needed package to setup the virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86df40-1ae5-4ad9-9b88-cd87333aff43",
   "metadata": {},
   "source": [
    "## **Installing the dependencies**\n",
    "This tutorial relies on several Python packages that have been developed as part of the **SPARC** project. We will be installing them in order to complete this tutorial. However, for each one of these packages, there is a GUI application that is available. Links to setting up each one of them will be provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcb5a50-148a-42d4-a984-d96c866dacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/mroe734/.local/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/mroe734/.local/lib/python3.10/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mroe734/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in /home/mroe734/.local/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /home/mroe734/.local/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c612c58-6029-4498-bc12-6afa6c8cfd2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Retrieving the data**\n",
    "Now that all the dependencies have been installed we will retrieve the data from directly from the [**SPARC**](https://sparc.science) project website. \n",
    "We will be using three datasets:\n",
    " * [vagal afferents associated with the myenteric plexus of the rat stomach](https://sparc.science/datasets/10?type=dataset&datasetDetailsTab=files)\n",
    " * [vagal afferents within the longitudinal and circular muscle layers of the rat stomach](https://sparc.science/datasets/11?type=dataset&datasetDetailsTab=files)\n",
    " * [vagal efferents associated with the myenteric plexus of the rat stomach](https://sparc.science/datasets/12?type=dataset&datasetDetailsTab=files)\n",
    " \n",
    "You can search through all of the **SPARC** datasets [here](https://sparc.science/data?type=dataset) or simply click on the links above to be redirected directly to the datasets. \n",
    "\n",
    "It is possible to downlowd the entire dataset by clicking on the purple ***Download full dataset*** button  in the **Download Dataset** tab or selecting specific files and folders in the **Dataset Files** tab lower in the page. If you haven't used the links above, you can click on the purple ***Get Dataset*** button on the left side of the screen or directly in the ***Files*** tab. \n",
    "\n",
    "For this tutorial, we are only interested in the contents of the _derative_ folder which contains two .xlsx files: one with the data (IGLE_data.xlsx, IMA_analyzed_data.xlsx, and Efferent_data.xlsx) and a manifest (manifest.xlsx). Enter the _derivative_ folder and select the xlsx file containing the data by ticking the box in front of it. Download the file by clicking the **Download Selected Files and Folders** button at the bottom. You will then be prompted to select the location in which to save it. For each dataset, save it in the _SPARC-tutorial_ folder. \n",
    "\n",
    "### **Pennsieve**\n",
    "[Pennsieve](https://app.pennsieve.io/) is the cloud-based solution for managing, analysing, and sharing scientific **SPARC** datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f332370-006a-4e4e-bf58-acda9f2d660b",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "Here we import all of the dependencies that we will need to run the code correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2cccacb-ac11-4313-ab0d-48072a51fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cc018-2386-48b6-8fc1-e831de2e56aa",
   "metadata": {},
   "source": [
    "Let us start with loading the data we have downloaded in Python.\n",
    "For this we are going to define some helper functions which relies on the pandas library.It will take as arguments the name of the .xlsx file we wish to load, the name of the columns we want to keep and the limits for the y and z direction. The output is a DataFrame called df with the desired columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e321aaf-0669-4acd-8b22-0aacaae34f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(percent, min_val, max_val):\n",
    "    \"\"\" Converts the position from percentage to distance\n",
    "    \n",
    "    Input:\n",
    "    percent -- float, percentage value.\n",
    "    min_val -- float, minimum distance for conversion.\n",
    "    max_val -- float, maximum distance for conversion.\n",
    "    \n",
    "    Return:\n",
    "    converted_value -- float, converted value.\n",
    "    \n",
    "    \"\"\"\n",
    "    return percent / 100 * (max_val - min_val) + min_val \n",
    "\n",
    "def load_data(data_name, col_keeps, y_lims, z_lims):\n",
    "    \"\"\" Loads the data from an .xlsx file\n",
    "    \n",
    "    Input:\n",
    "    data_name -- str, nane of the .xlsx file to read.\n",
    "    col_keeps -- dict{str:str}, dictionnary containing the names of the columns\n",
    "        to keep.\n",
    "    y_lims -- list[int], limits for the y direction to convert back to mm,\n",
    "            first element is the minimum and second is the maximum.\n",
    "    z_lims -- list[int], limits for the z direction to convert back to mm,\n",
    "        first element is the minimum and second is the maximum.\n",
    "    \n",
    "    Return:\n",
    "    df -- DataFrame, data frame containing the desired data.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_excel(data_name)\n",
    "    # remove unnecessary columns\n",
    "    for col in df.columns:\n",
    "        if col in col_keeps:\n",
    "            df.rename(columns = {col:col_keeps[col]}, inplace = True)\n",
    "        else:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    df['y'] = get_position(df['%y'], y_lims[0], y_lims[1])\n",
    "    df['z'] = get_position(df['%x'], z_lims[0], z_lims[1]) # x becomes z\n",
    "    df['-%y'] = 100 - df['%y']\n",
    "    # change the area to mm\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4172ad9-feb7-4b7d-89bf-fa3ddf1f932d",
   "metadata": {},
   "source": [
    "Now, let us setup some variables that we will need to prepare the data for mapping and plotting. In these datasets, the distances are in percentages and we need to define the references to convert them back in mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868f7e0a-e0bb-484c-9916-1b629673a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup maximimum x and y width\n",
    "z_lims = [0, 36.7]\n",
    "y_lims = [4.6, 0]\n",
    "\n",
    "col_keeps = {'%x (distance from pylorus side)':'%x', '%y (distance from bottom)':'%y',\n",
    "             'Average IGLE Area (um²)':'area', 'Area Of Innervation':'area', \n",
    "             'Neuron Area Of Innervation (um²) -Convex Hull':'area'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489af2e-2fb7-4139-9696-c16732c898cb",
   "metadata": {},
   "source": [
    "We can now load the locations of the nerves into DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b000479-2aaf-49c6-8e1a-8915ff7a7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_igle = load_data('IGLE_data.xlsx', col_keeps, y_lims, z_lims)\n",
    "df_ima = load_data('IMA_analyzed_data.xlsx', col_keeps, y_lims, z_lims)\n",
    "df_efferent = load_data('Efferent_data.xlsx', col_keeps, y_lims, z_lims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f764e-4eab-47f6-81e2-01f6b5e73e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
