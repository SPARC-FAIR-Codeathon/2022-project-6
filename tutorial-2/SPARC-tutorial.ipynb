{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fbbad7-cc5c-4fd5-bcc7-e5493398afcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **<center>SPARC FAIR Codeathon 2022</center>**\n",
    "<center>\n",
    "<a href=\"https://sparc.science\">\n",
    "<img src=\"https://sparc.science/_nuxt/img/logo-sparc-wave-primary.8ed83a5.svg\" alt=\"SPARC\" width=\"150\"/>\n",
    "</a>\n",
    "</center>\n",
    "<center>\n",
    "<a href=\"https://sparc.science/help/2022-sparc-fair-codeathon\">\n",
    "<img src=\"https://images.ctfassets.net/6bya4tyw8399/2qgsOmFnm7wYIfRrPrqbgx/ae3255858aa12bfcebb52e95c7cacffe/codeathon-graphic.png\" alt=\"FAIR\" width=\"75\">\n",
    "</a>\n",
    "</center>\n",
    "\n",
    "## <center>Tutorial 2: Resampling data for simulations</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde64e8-4021-4a6b-bae7-b90b40239999",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Introduction**\n",
    "Welcome to the first of the Quilted Tutorials! We will be demonstrating different features from the [**SPARC**](https://sparc.science/) project. The goal will be to project the 2D locations of neurites in the rat stomach onto a 3D scaffhold of the organ. The data points and the 3D scaffhold will be pulled from **SPARC** datasets. Because the data is [**FAIR**](https://www.nature.com/articles/sdata201618) we will be combining three different datasets of the spatial distribution of the vagal afferents and efferents. Here is the workflow for this tutorial\n",
    "\n",
    "![workflow](img/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86df40-1ae5-4ad9-9b88-cd87333aff43",
   "metadata": {},
   "source": [
    "## **Installing the dependencies**\n",
    "This tutorial relies on several Python packages that have been developed as part of the **SPARC** project. We will be installing them in order to complete this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb5a50-148a-42d4-a984-d96c866dacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas # To load SPARC datasets in Python\n",
    "!pip install openpyxl # Pandas complement for Microsoft Excel files\n",
    "!pip install ipywidgets # To interact with plotted data\n",
    "# For data visualisation\n",
    "!pip install numpy\n",
    "!pip install numpy-stl\n",
    "!pip install matplotlib\n",
    "!pip install ipympl\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c612c58-6029-4498-bc12-6afa6c8cfd2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Retrieving the data**\n",
    "Now that all the dependencies have been installed we will retrieve the data from directly from the [**SPARC**](https://sparc.science) project website. \n",
    "We will be using three datasets:\n",
    " * [vagal afferents associated with the myenteric plexus of the rat stomach](https://sparc.science/datasets/10?type=dataset&datasetDetailsTab=files)\n",
    " * [vagal afferents within the longitudinal and circular muscle layers of the rat stomach](https://sparc.science/datasets/11?type=dataset&datasetDetailsTab=files)\n",
    " * [vagal efferents associated with the myenteric plexus of the rat stomach](https://sparc.science/datasets/12?type=dataset&datasetDetailsTab=files)\n",
    " \n",
    "You can search through all of the **SPARC** datasets [here](https://sparc.science/data?type=dataset) or simply click on the links above to be redirected directly to the datasets. \n",
    "\n",
    "It is possible to downlowd the entire dataset by clicking on the purple ***Download full dataset*** button  in the **Download Dataset** tab or selecting specific files and folders in the **Dataset Files** tab lower in the page. If you haven't used the links above, you can click on the purple ***Get Dataset*** button on the left side of the screen or directly in the ***Files*** tab. \n",
    "\n",
    "For this tutorial, we are only interested in the contents of the _derative_ folder which contains two .xlsx files: one with the data (IGLE_data.xlsx, IMA_analyzed_data.xlsx, and Efferent_data.xlsx) and a manifest (manifest.xlsx). Enter the _derivative_ folder and select the xlsx file containing the data by ticking the box in front of it. Download the file by clicking the **Download Selected Files and Folders** button at the bottom. You will then be prompted to select the location in which to save it. For each dataset, save it in the _SPARC-tutorial_ folder. \n",
    "\n",
    "#### ⚠️  **SPARC Guru tip**: \n",
    "Ever heard of Pennsieve? It's the **SPARC** tool to use if you want to avoid downloading the data manually. It even has a Python API so you can integrate it directly into this Notebook! Check out the [documentation](https://docs.pennsieve.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f332370-006a-4e4e-bf58-acda9f2d660b",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "Here we import all of the dependencies that we will need to run the code correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cccacb-ac11-4313-ab0d-48072a51fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from stl import mesh as msh\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import scipy.stats as st\n",
    "from ipywidgets import interact, Checkbox, fixed, ToggleButtons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1122c6-7110-4351-998d-1e93e7aaf9cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Helper functions**\n",
    "Now that we have installed and imported the required dependencies, we are going to define some helper functions.\n",
    "\n",
    "#### _get\\_position_\n",
    "This function will allow use to convert the position of the data from a percentage into a distance in mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e321aaf-0669-4acd-8b22-0aacaae34f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(percent, min_val, max_val):\n",
    "    \"\"\" Converts the position from percentage to distance.\n",
    "    \n",
    "    Inputs:\n",
    "    percent -- float, percentage value.\n",
    "    min_val -- float, minimum distance for conversion.\n",
    "    max_val -- float, maximum distance for conversion.\n",
    "    \n",
    "    Outputs:\n",
    "    converted_value -- float, converted value.\n",
    "    \n",
    "    \"\"\"\n",
    "    return percent / 100 * (max_val - min_val) + min_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8fd96b-bfd2-412e-83ea-8b14dbc80bd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### _load\\_data_\n",
    "This function will allow use to extract the correct elements inside the data files and store them into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aab3c46-8946-4e7b-b1ac-64d4ab546ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name, col_keeps, x_lims, y_lims):\n",
    "    \"\"\" Loads the data from an .xlsx file.\n",
    "    \n",
    "    Inputs:\n",
    "    data_name -- str, nane of the .xlsx file to read.\n",
    "    col_keeps -- dict{str:str}, dictionnary containing the names of the columns\n",
    "        to keep.\n",
    "    x_lims -- list[int], limits for the x direction to convert back to mm,\n",
    "            first element is the minimum and second is the maximum.\n",
    "    y_lims -- list[int], limits for the y direction to convert back to mm,\n",
    "        first element is the minimum and second is the maximum.\n",
    "    \n",
    "    Outputs:\n",
    "    df -- DataFrame, data frame containing the desired data.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_excel(data_name)\n",
    "    # remove unnecessary columns\n",
    "    for col in df.columns:\n",
    "        if col in col_keeps:\n",
    "            df.rename(columns = {col:col_keeps[col]}, inplace = True)\n",
    "        else:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    df['y'] = get_position(df['%y'], y_lims[0], y_lims[1])\n",
    "    df['x'] = get_position(df['%x'], x_lims[0], x_lims[1])\n",
    "    df['-%y'] = 100 - df['%y']\n",
    "    # change the area to mm\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14496640-67ff-4b56-9151-e707eb2c94a3",
   "metadata": {},
   "source": [
    "#### _prepare\\_data_\n",
    "This function will prepare the data to be plotted. \n",
    "------ Explain here that the data is being resampled so that it can be used for sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03974a6-4f8f-41e6-b944-c701c87f15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\" Prepares the data to be plotted by creating the probablity estimates and the sampled points.\n",
    "    \n",
    "    Inputs:\n",
    "    df -- \n",
    "    Outputs:\n",
    "    \n",
    "    \"\"\"\n",
    "    data_array = df\n",
    "    data_array = data_array[~data_array.isin([np.nan]).any(1)]\n",
    "\n",
    "    # Extract x and y\n",
    "    x = np.array(data_array['x'])\n",
    "    y = np.array(data_array['y'])\n",
    "\n",
    "    # Create meshgrid\n",
    "    xx, yy = np.mgrid[x_lims[0]:x_lims[1]:100j, y_lims[0]:y_lims[1]:100j]\n",
    "\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = st.gaussian_kde(values)\n",
    "    prob_estimate = np.reshape(kernel(positions).T, xx.shape)\n",
    "\n",
    "    sampled_pts = kernel.resample(1000).T\n",
    "    \n",
    "    return xx, yy, prob_estimate, sampled_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4172ad9-feb7-4b7d-89bf-fa3ddf1f932d",
   "metadata": {},
   "source": [
    "### **Loading the 2D data**\n",
    "In the 2D datasets that we are using, the distances are in percentages relative to an origin situated in the pyloric end of the stomach for the y-axis and near the oesophagus for the z-axis. We are going to convert those into millimeters instead. For this, we are going to define the limits in the z- and y-axis. \n",
    "\n",
    "Here is a 2D representation of the data we are going to map to the 3D mesh.\n",
    "![2d](img/2d_data_viz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868f7e0a-e0bb-484c-9916-1b629673a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup maximimum y and z widths based on scale in image.\n",
    "x_lims = [0, 36.7]\n",
    "y_lims = [24.6, 0]\n",
    "\n",
    "col_keeps = {'%x (distance from pylorus side)':'%x', '%y (distance from bottom)':'%y'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489af2e-2fb7-4139-9696-c16732c898cb",
   "metadata": {},
   "source": [
    "We can now load the locations of the nerves into data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b000479-2aaf-49c6-8e1a-8915ff7a7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "igle_df = load_data('res/IGLE_data.xlsx', col_keeps, x_lims, y_lims)\n",
    "ima_df = load_data('res/IMA_analyzed_data.xlsx', col_keeps, x_lims, y_lims)\n",
    "efferent_df = load_data('res/Efferent_data.xlsx', col_keeps, x_lims, y_lims) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c51a2-15a2-4ded-b67b-6c3d3a43ba57",
   "metadata": {},
   "source": [
    "### **Preparing the 2D data**\n",
    "Now that we have loaded are datasets into Python, we are going to prepare to be mapped then plotted. For this, we are going to use our _convert_2D_data_ helper function. This will convert our data from the pandas DataFrame to a numpy array which will be more easy to manipulate for our objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2a7408-73b9-4254-8c38-d1c19b756316",
   "metadata": {},
   "outputs": [],
   "source": [
    "efferent_xx, efferent_yy, efferent_est, efferent_pts = prepare_data(efferent_df)\n",
    "ima_xx, ima_yy, ima_est, ima_pts = prepare_data(ima_df)\n",
    "igle_xx, igle_yy, igle_est, igle_pts = prepare_data(igle_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa87c1-6cfe-42d0-a880-ddce65a50821",
   "metadata": {},
   "source": [
    "### **Visualising data**\n",
    "The data has now been mapped to the 3D mesh. All that is left to do is visualise the mesh and the nerves! We are going to be using the matplotlib package to visualise the data. We define a plotting function to be able to create an interactive interface. We create three checkboxes, one for each dataset, in order to visulasie the points from each data set individually. The efferents are plotted in green, the IMAs are plotted in red, and the igle are plotted in blue. You can select the data by ticking or unticking the boxes. \n",
    "\n",
    "#### ⚠️  **SPARC Guru tip**: \n",
    "Did you know that there are some **SPARC** tools that you can use to visualise the data? They have their own GUI that you can use. For this tutorial, we decided to keep everything in one place but they also have compatible Python APIs that will allow you to integrate the tool directly into this Notebook! Take a look [here](link to tool) to read the documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387d707a-0a7d-4d44-8163-0ab5b936de48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e584654a7c594e5081458b0214dc9dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sel', options=('Efferent', 'IGLE', 'IMA'), value='Efferent'), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotting_fct(efferent_xx, efferent_yy, efferent_est, efferent_pts, ima_xx, ima_yy, ima_est, ima_pts, igle_xx, igle_yy, igle_est, igle_pts, sel)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable interactivity in jupyterlab.\n",
    "%matplotlib widget \n",
    "\n",
    "def plotting_fct(efferent_xx, efferent_yy, efferent_est, efferent_pts,\n",
    "                 ima_xx, ima_yy, ima_est, ima_pts,\n",
    "                 igle_xx, igle_yy, igle_est, igle_pts,\n",
    "                 sel):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    ax.set_xlim(x_lims[0], x_lims[1])\n",
    "    ax.set_ylim(y_lims[1], y_lims[0])\n",
    "\n",
    "    if sel == 'Efferent':\n",
    "        cfset = ax.contourf(efferent_xx, efferent_yy, efferent_est, levels=1000,cmap='coolwarm')\n",
    "        ax.imshow(np.rot90(efferent_est), cmap='coolwarm', extent=[x_lims[0], x_lims[1], y_lims[0], y_lims[1]])\n",
    "        ax.scatter(efferent_pts[:, 0], efferent_pts[:, 1], s=5, color='g')\n",
    "\n",
    "    if sel == 'IMA':\n",
    "        cfset = ax.contourf(ima_xx, ima_yy, ima_est, levels=1000,cmap='coolwarm')\n",
    "        ax.imshow(np.rot90(ima_est), cmap='coolwarm', extent=[x_lims[0], x_lims[1], y_lims[0], y_lims[1]])        \n",
    "        ax.scatter(ima_pts[:, 0], ima_pts[:, 1], s=5, color='g')\n",
    "\n",
    "    if sel == 'IGLE':\n",
    "        cfset = ax.contourf(igle_xx, igle_yy, igle_est, levels=1000,cmap='coolwarm')\n",
    "        ax.imshow(np.rot90(igle_est), cmap='coolwarm', extent=[x_lims[0], x_lims[1], y_lims[0], y_lims[1]])        \n",
    "        ax.scatter(igle_pts[:, 0], igle_pts[:, 1], s=5, color='g')\n",
    "\n",
    "    ax.set_xlabel('X (mm)')\n",
    "    ax.set_ylabel('Y (mm)')\n",
    "    plt.title('Gaussian Kernel density estimation')\n",
    "    plt.show()\n",
    "\n",
    "def onToggle(btn):\n",
    "    plotting_fct(efferent_xx=efferent_xx, efferent_yy=efferent_yy, efferent_est=efferent_est, efferent_pts=efferent_pts, \n",
    "         ima_xx=ima_xx, ima_yy=ima_yy, ima_est=ima_est, ima_pts=ima_pts, \n",
    "         igle_xx=igle_xx, igle_yy=igle_yy, igle_est=igle_est, igle_pts=igle_pts, sel=btn.owner.value)\n",
    "\n",
    "# tb=ToggleButtons(\n",
    "#     options=['Efferent', 'IGLE', 'IMA'],\n",
    "#     description='Dataset:',\n",
    "#     disabled=False,\n",
    "#     button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#     tooltips=['Efferent', 'IGLE', 'IMA'],\n",
    "# #     icons=['check'] * 3\n",
    "# )\n",
    "  \n",
    "# tb.observe(onToggle, names=['value']) \n",
    "# display(tb)\n",
    "\n",
    "interact(plotting_fct, efferent_xx=fixed(efferent_xx), efferent_yy=fixed(efferent_yy), efferent_est=fixed(efferent_est), efferent_pts=fixed(efferent_pts), \n",
    "         ima_xx=fixed(ima_xx), ima_yy=fixed(ima_yy), ima_est=fixed(ima_est), ima_pts=fixed(ima_pts), \n",
    "         igle_xx=fixed(igle_xx), igle_yy=fixed(igle_yy), igle_est=fixed(igle_est), igle_pts=fixed(igle_pts), \n",
    "         sel=['Efferent', 'IGLE', 'IMA'])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e7ecb-389c-42ff-995e-ef700b6501a4",
   "metadata": {},
   "source": [
    "### **Congratulations**\n",
    "You have successfully completed your first Quilted Tutorial and are now on your way to becoming a **SPARC** Guru! \n",
    "\n",
    "We invite you to reuse this tutorial and explore the possibilities of using **SPARC** tools when possible. Try different things, such as adding ***your own code*** to generate a new stomach mesh with INSERT TOOL NAME. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
